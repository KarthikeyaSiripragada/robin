{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force all text file opens to use UTF-8\n",
    "import builtins\n",
    "_orig_open = builtins.open\n",
    "def _open_utf8(path, mode='r', *args, **kwargs):\n",
    "    if 'b' not in mode:\n",
    "        kwargs.setdefault('encoding', 'utf-8')\n",
    "    return _orig_open(path, mode, *args, **kwargs)\n",
    "builtins.open = _open_utf8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x81 in position 1980: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrobin\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RobinConfiguration\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Explicitly tell Robin to use gpt-3.5-turbo\u001b[39;00m\n\u001b[32m      4\u001b[39m cfg = RobinConfiguration(llm_model=\u001b[33m\"\u001b[39m\u001b[33mgpt-3.5-turbo\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\robin\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01manalyses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data_analysis\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01massays\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m experimental_assay\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcandidates\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m therapeutic_candidates\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\robin\\analyses.py:5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cast\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maviary\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Message\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RobinConfiguration\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmultitrajectory_runner\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Step, StepConfig\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\aviary\\core.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maviary\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataset_server\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TaskDatasetServer\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maviary\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      3\u001b[39m     TASK_DATASET_REGISTRY,\n\u001b[32m      4\u001b[39m     DummyEnv,\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m     TaskDataset,\n\u001b[32m     11\u001b[39m )\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maviary\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menv_client\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     13\u001b[39m     EnvironmentClient,\n\u001b[32m     14\u001b[39m     TaskDatasetClient,\n\u001b[32m     15\u001b[39m     TaskEnvClientState,\n\u001b[32m     16\u001b[39m     TaskEnvironmentClient,\n\u001b[32m     17\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\aviary\\dataset_server.py:13\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Generic, TypeVar\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Field\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maviary\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Environment, TaskDataset\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maviary\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MessagesAdapter, ToolRequestMessage, ToolsAdapter\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\aviary\\env.py:24\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Annotated, Generic, Self, TypeAlias, TypeVar, cast\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     15\u001b[39m     BaseModel,\n\u001b[32m     16\u001b[39m     ConfigDict,\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m     field_validator,\n\u001b[32m     22\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maviary\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Message\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maviary\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     26\u001b[39m     Messages,\n\u001b[32m     27\u001b[39m     Tool,\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     ToolResponseMessage,\n\u001b[32m     31\u001b[39m )\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maviary\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m format_exc, is_coroutine_callable\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\aviary\\message.py:9\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, ClassVar, Self\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Field, field_validator, model_validator\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maviary\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m encode_image_to_base64, validate_base64_image\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogRecord\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\aviary\\utils.py:17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic_core\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m core_schema \u001b[38;5;28;01mas\u001b[39;00m cs\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlitellm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m acompletion\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m     19\u001b[39m     acompletion = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\__init__.py:762\u001b[39m\n\u001b[32m    759\u001b[39m openai_image_generation_models = [\u001b[33m\"\u001b[39m\u001b[33mdall-e-2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdall-e-3\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtimeout\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m timeout\n\u001b[32m--> \u001b[39m\u001b[32m762\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcost_calculator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m completion_cost\n\u001b[32m    763\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlitellm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlitellm_core_utils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlitellm_logging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Logging, modify_integration\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlitellm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlitellm_core_utils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mget_llm_provider_logic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_llm_provider\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\cost_calculator.py:19\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlitellm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     13\u001b[39m     DEFAULT_MAX_LRU_CACHE_SIZE,\n\u001b[32m     14\u001b[39m     DEFAULT_REPLICATE_GPU_PRICE_PER_SECOND,\n\u001b[32m     15\u001b[39m )\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlitellm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlitellm_core_utils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllm_cost_calc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtool_call_cost_tracking\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     StandardBuiltInToolCostTracking,\n\u001b[32m     18\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlitellm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlitellm_core_utils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllm_cost_calc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     20\u001b[39m     _generic_cost_per_character,\n\u001b[32m     21\u001b[39m     generic_cost_per_token,\n\u001b[32m     22\u001b[39m )\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlitellm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01manthropic\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcost_calculation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     24\u001b[39m     cost_per_token \u001b[38;5;28;01mas\u001b[39;00m anthropic_cost_per_token,\n\u001b[32m     25\u001b[39m )\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlitellm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mazure\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcost_calculation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     27\u001b[39m     cost_per_token \u001b[38;5;28;01mas\u001b[39;00m azure_openai_cost_per_token,\n\u001b[32m     28\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\litellm_core_utils\\llm_cost_calc\\utils.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlitellm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m verbose_logger\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlitellm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelInfo, Usage\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlitellm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_model_info\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_is_above_128k\u001b[39m(tokens: \u001b[38;5;28mfloat\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tokens > \u001b[32m128000\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\utils.py:188\u001b[39m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    184\u001b[39m     \u001b[38;5;66;03m# Python 3.9+\u001b[39;00m\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m resources.files(\u001b[33m\"\u001b[39m\u001b[33mlitellm.litellm_core_utils.tokenizers\u001b[39m\u001b[33m\"\u001b[39m).joinpath(\n\u001b[32m    186\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33manthropic_tokenizer.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    187\u001b[39m     ).open(\u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m         json_data = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m resources.open_text(\n\u001b[32m    191\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlitellm.litellm_core_utils.tokenizers\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33manthropic_tokenizer.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    192\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(fp, *, \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, object_hook=\u001b[38;5;28;01mNone\u001b[39;00m, parse_float=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    275\u001b[39m         parse_int=\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant=\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook=\u001b[38;5;28;01mNone\u001b[39;00m, **kw):\n\u001b[32m    276\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    294\u001b[39m         \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m         parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\cp1252.py:23\u001b[39m, in \u001b[36mIncrementalDecoder.decode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcharmap_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'charmap' codec can't decode byte 0x81 in position 1980: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "from robin.configuration import RobinConfiguration\n",
    "\n",
    "# Explicitly tell Robin to use gpt-3.5-turbo\n",
    "cfg = RobinConfiguration(llm_model=\"gpt-3.5-turbo\")\n",
    "print(cfg.llm_client.config[\"model_list\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_MODEL = gpt-3.5-turbo\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"OPENAI_MODEL =\", os.getenv(\"OPENAI_MODEL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x81 in position 1980: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrobin\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RobinConfiguration\n\u001b[32m      2\u001b[39m cfg = RobinConfiguration()\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(cfg.llm_client.\u001b[34m__dict__\u001b[39m.get(\u001b[33m\"\u001b[39m\u001b[33mmodel_name\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m cfg.llm_client.\u001b[34m__dict__\u001b[39m.get(\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mrepr\u001b[39m(cfg.llm_client))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\robin\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01manalyses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data_analysis\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01massays\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m experimental_assay\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcandidates\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m therapeutic_candidates\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\robin\\analyses.py:5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cast\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maviary\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Message\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RobinConfiguration\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmultitrajectory_runner\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Step, StepConfig\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\aviary\\core.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maviary\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataset_server\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TaskDatasetServer\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maviary\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      3\u001b[39m     TASK_DATASET_REGISTRY,\n\u001b[32m      4\u001b[39m     DummyEnv,\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m     TaskDataset,\n\u001b[32m     11\u001b[39m )\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maviary\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menv_client\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     13\u001b[39m     EnvironmentClient,\n\u001b[32m     14\u001b[39m     TaskDatasetClient,\n\u001b[32m     15\u001b[39m     TaskEnvClientState,\n\u001b[32m     16\u001b[39m     TaskEnvironmentClient,\n\u001b[32m     17\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\aviary\\dataset_server.py:13\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Generic, TypeVar\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Field\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maviary\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Environment, TaskDataset\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maviary\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MessagesAdapter, ToolRequestMessage, ToolsAdapter\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\aviary\\env.py:24\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Annotated, Generic, Self, TypeAlias, TypeVar, cast\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     15\u001b[39m     BaseModel,\n\u001b[32m     16\u001b[39m     ConfigDict,\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m     field_validator,\n\u001b[32m     22\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maviary\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Message\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maviary\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     26\u001b[39m     Messages,\n\u001b[32m     27\u001b[39m     Tool,\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     ToolResponseMessage,\n\u001b[32m     31\u001b[39m )\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maviary\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m format_exc, is_coroutine_callable\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\aviary\\message.py:9\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, ClassVar, Self\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Field, field_validator, model_validator\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maviary\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m encode_image_to_base64, validate_base64_image\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogRecord\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\aviary\\utils.py:17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic_core\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m core_schema \u001b[38;5;28;01mas\u001b[39;00m cs\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlitellm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m acompletion\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m     19\u001b[39m     acompletion = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\__init__.py:762\u001b[39m\n\u001b[32m    759\u001b[39m openai_image_generation_models = [\u001b[33m\"\u001b[39m\u001b[33mdall-e-2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdall-e-3\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtimeout\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m timeout\n\u001b[32m--> \u001b[39m\u001b[32m762\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcost_calculator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m completion_cost\n\u001b[32m    763\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlitellm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlitellm_core_utils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlitellm_logging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Logging, modify_integration\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlitellm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlitellm_core_utils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mget_llm_provider_logic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_llm_provider\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\cost_calculator.py:19\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlitellm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     13\u001b[39m     DEFAULT_MAX_LRU_CACHE_SIZE,\n\u001b[32m     14\u001b[39m     DEFAULT_REPLICATE_GPU_PRICE_PER_SECOND,\n\u001b[32m     15\u001b[39m )\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlitellm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlitellm_core_utils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllm_cost_calc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtool_call_cost_tracking\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     StandardBuiltInToolCostTracking,\n\u001b[32m     18\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlitellm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlitellm_core_utils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllm_cost_calc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     20\u001b[39m     _generic_cost_per_character,\n\u001b[32m     21\u001b[39m     generic_cost_per_token,\n\u001b[32m     22\u001b[39m )\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlitellm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01manthropic\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcost_calculation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     24\u001b[39m     cost_per_token \u001b[38;5;28;01mas\u001b[39;00m anthropic_cost_per_token,\n\u001b[32m     25\u001b[39m )\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlitellm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mazure\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcost_calculation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     27\u001b[39m     cost_per_token \u001b[38;5;28;01mas\u001b[39;00m azure_openai_cost_per_token,\n\u001b[32m     28\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\litellm_core_utils\\llm_cost_calc\\utils.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlitellm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m verbose_logger\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlitellm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelInfo, Usage\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlitellm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_model_info\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_is_above_128k\u001b[39m(tokens: \u001b[38;5;28mfloat\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tokens > \u001b[32m128000\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\utils.py:188\u001b[39m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    184\u001b[39m     \u001b[38;5;66;03m# Python 3.9+\u001b[39;00m\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m resources.files(\u001b[33m\"\u001b[39m\u001b[33mlitellm.litellm_core_utils.tokenizers\u001b[39m\u001b[33m\"\u001b[39m).joinpath(\n\u001b[32m    186\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33manthropic_tokenizer.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    187\u001b[39m     ).open(\u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m         json_data = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m resources.open_text(\n\u001b[32m    191\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlitellm.litellm_core_utils.tokenizers\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33manthropic_tokenizer.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    192\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(fp, *, \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, object_hook=\u001b[38;5;28;01mNone\u001b[39;00m, parse_float=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    275\u001b[39m         parse_int=\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant=\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook=\u001b[38;5;28;01mNone\u001b[39;00m, **kw):\n\u001b[32m    276\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    294\u001b[39m         \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m         parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\cp1252.py:23\u001b[39m, in \u001b[36mIncrementalDecoder.decode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcharmap_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'charmap' codec can't decode byte 0x81 in position 1980: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "from robin.configuration import RobinConfiguration\n",
    "cfg = RobinConfiguration()\n",
    "print(cfg.llm_client.__dict__.get(\"model_name\") or cfg.llm_client.__dict__.get(\"model\") or repr(cfg.llm_client))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "litellm.NotFoundError: OpenAIException - Your organization must be verified to use the model `o4-mini`. Please go to: https://platform.openai.com/settings/organization/general and click on Verify Organization. If you just verified, it can take up to 15 minutes for access to propagate.. Received Model Group=o4-mini\nAvailable Model Group Fallbacks=None",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFoundError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\llms\\openai\\openai.py:790\u001b[39m, in \u001b[36mOpenAIChatCompletion.acompletion\u001b[39m\u001b[34m(self, data, model, model_response, logging_obj, timeout, api_key, api_base, api_version, organization, client, max_retries, headers, drop_params, stream_options, fake_stream)\u001b[39m\n\u001b[32m    777\u001b[39m logging_obj.pre_call(\n\u001b[32m    778\u001b[39m     \u001b[38;5;28minput\u001b[39m=data[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    779\u001b[39m     api_key=openai_aclient.api_key,\n\u001b[32m   (...)\u001b[39m\u001b[32m    787\u001b[39m     },\n\u001b[32m    788\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m headers, response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.make_openai_chat_completion_request(\n\u001b[32m    791\u001b[39m     openai_aclient=openai_aclient,\n\u001b[32m    792\u001b[39m     data=data,\n\u001b[32m    793\u001b[39m     timeout=timeout,\n\u001b[32m    794\u001b[39m     logging_obj=logging_obj,\n\u001b[32m    795\u001b[39m )\n\u001b[32m    796\u001b[39m stringified_response = response.model_dump()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\litellm_core_utils\\logging_utils.py:135\u001b[39m, in \u001b[36mtrack_llm_api_timing.<locals>.decorator.<locals>.async_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\llms\\openai\\openai.py:436\u001b[39m, in \u001b[36mOpenAIChatCompletion.make_openai_chat_completion_request\u001b[39m\u001b[34m(self, openai_aclient, data, timeout, logging_obj)\u001b[39m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m436\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\llms\\openai\\openai.py:418\u001b[39m, in \u001b[36mOpenAIChatCompletion.make_openai_chat_completion_request\u001b[39m\u001b[34m(self, openai_aclient, data, timeout, logging_obj)\u001b[39m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    417\u001b[39m     raw_response = (\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m openai_aclient.chat.completions.with_raw_response.create(\n\u001b[32m    419\u001b[39m             **data, timeout=timeout\n\u001b[32m    420\u001b[39m         )\n\u001b[32m    421\u001b[39m     )\n\u001b[32m    422\u001b[39m     end_time = time.time()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\openai\\_legacy_response.py:381\u001b[39m, in \u001b[36masync_to_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    379\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m381\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:2454\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   2453\u001b[39m validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m2454\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   2455\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2456\u001b[39m     body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   2457\u001b[39m         {\n\u001b[32m   2458\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   2459\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   2460\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m   2461\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   2462\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   2463\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   2464\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m   2465\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m   2466\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m   2467\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   2468\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   2469\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m   2470\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m   2471\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   2472\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m   2473\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m   2474\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m   2475\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m   2476\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m   2477\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   2478\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m   2479\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   2480\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   2481\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   2482\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   2483\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   2484\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   2485\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   2486\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   2487\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   2488\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mweb_search_options\u001b[39m\u001b[33m\"\u001b[39m: web_search_options,\n\u001b[32m   2489\u001b[39m         },\n\u001b[32m   2490\u001b[39m         completion_create_params.CompletionCreateParamsStreaming\n\u001b[32m   2491\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   2492\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m completion_create_params.CompletionCreateParamsNonStreaming,\n\u001b[32m   2493\u001b[39m     ),\n\u001b[32m   2494\u001b[39m     options=make_request_options(\n\u001b[32m   2495\u001b[39m         extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   2496\u001b[39m     ),\n\u001b[32m   2497\u001b[39m     cast_to=ChatCompletion,\n\u001b[32m   2498\u001b[39m     stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   2499\u001b[39m     stream_cls=AsyncStream[ChatCompletionChunk],\n\u001b[32m   2500\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1791\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1788\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1789\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1790\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1791\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1591\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1590\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1591\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1593\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mNotFoundError\u001b[39m: Error code: 404 - {'error': {'message': 'Your organization must be verified to use the model `o4-mini`. Please go to: https://platform.openai.com/settings/organization/general and click on Verify Organization. If you just verified, it can take up to 15 minutes for access to propagate.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\main.py:478\u001b[39m, in \u001b[36macompletion\u001b[39m\u001b[34m(model, messages, functions, function_call, timeout, temperature, top_p, n, stream, stream_options, stop, max_tokens, max_completion_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, parallel_tool_calls, logprobs, top_logprobs, deployment_id, reasoning_effort, base_url, api_version, api_key, model_list, extra_headers, thinking, **kwargs)\u001b[39m\n\u001b[32m    477\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m asyncio.iscoroutine(init_response):\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m init_response\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\llms\\openai\\openai.py:837\u001b[39m, in \u001b[36mOpenAIChatCompletion.acompletion\u001b[39m\u001b[34m(self, data, model, model_response, logging_obj, timeout, api_key, api_base, api_version, organization, client, max_retries, headers, drop_params, stream_options, fake_stream)\u001b[39m\n\u001b[32m    835\u001b[39m message = \u001b[38;5;28mgetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(e))\n\u001b[32m--> \u001b[39m\u001b[32m837\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    838\u001b[39m     status_code=status_code,\n\u001b[32m    839\u001b[39m     message=message,\n\u001b[32m    840\u001b[39m     headers=error_headers,\n\u001b[32m    841\u001b[39m     body=exception_body,\n\u001b[32m    842\u001b[39m )\n",
      "\u001b[31mOpenAIError\u001b[39m: Error code: 404 - {'error': {'message': 'Your organization must be verified to use the model `o4-mini`. Please go to: https://platform.openai.com/settings/organization/general and click on Verify Organization. If you just verified, it can take up to 15 minutes for access to propagate.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNotFoundError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrobin\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01massays\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m experimental_assay\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m experimental_assay(configuration=cfg)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\robin\\assays.py:53\u001b[39m, in \u001b[36mexperimental_assay\u001b[39m\u001b[34m(configuration)\u001b[39m\n\u001b[32m     41\u001b[39m assay_literature_user_message = (\n\u001b[32m     42\u001b[39m     configuration.prompts.assay_literature_user_message.format(\n\u001b[32m     43\u001b[39m         num_queries=configuration.num_queries,\n\u001b[32m     44\u001b[39m         disease_name=configuration.disease_name,\n\u001b[32m     45\u001b[39m     )\n\u001b[32m     46\u001b[39m )\n\u001b[32m     48\u001b[39m assay_literature_query_messages = [\n\u001b[32m     49\u001b[39m     Message(role=\u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, content=assay_literature_system_message),\n\u001b[32m     50\u001b[39m     Message(role=\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, content=assay_literature_user_message),\n\u001b[32m     51\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m assay_literature_query_result = \u001b[38;5;28;01mawait\u001b[39;00m configuration.llm_client.call_single(\n\u001b[32m     54\u001b[39m     assay_literature_query_messages\n\u001b[32m     55\u001b[39m )\n\u001b[32m     57\u001b[39m assay_literature_query_result_text = cast(\u001b[38;5;28mstr\u001b[39m, assay_literature_query_result.text)\n\u001b[32m     58\u001b[39m assay_literature_queries = assay_literature_query_result_text.split(\u001b[33m\"\u001b[39m\u001b[33m<>\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\lmi\\llms.py:389\u001b[39m, in \u001b[36mLLMModel.call_single\u001b[39m\u001b[34m(self, messages, callbacks, name, output_type, tools, tool_choice, **kwargs)\u001b[39m\n\u001b[32m    386\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(messages, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    387\u001b[39m     \u001b[38;5;66;03m# convenience for single message\u001b[39;00m\n\u001b[32m    388\u001b[39m     messages = [Message(content=messages)]\n\u001b[32m--> \u001b[39m\u001b[32m389\u001b[39m results = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.call(\n\u001b[32m    390\u001b[39m     messages,\n\u001b[32m    391\u001b[39m     callbacks,\n\u001b[32m    392\u001b[39m     name,\n\u001b[32m    393\u001b[39m     output_type,\n\u001b[32m    394\u001b[39m     tools,\n\u001b[32m    395\u001b[39m     tool_choice,\n\u001b[32m    396\u001b[39m     n=\u001b[32m1\u001b[39m,\n\u001b[32m    397\u001b[39m     **kwargs,\n\u001b[32m    398\u001b[39m )\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(results) != \u001b[32m1\u001b[39m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;66;03m# Can be caused by issues like https://github.com/BerriAI/litellm/issues/12298\u001b[39;00m\n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m results when expecting just one.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\lmi\\llms.py:335\u001b[39m, in \u001b[36mLLMModel.call\u001b[39m\u001b[34m(self, messages, callbacks, name, output_type, tools, tool_choice, **kwargs)\u001b[39m\n\u001b[32m    333\u001b[39m start_clock = asyncio.get_running_loop().time()\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m callbacks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     results = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.acompletion(messages, **chat_kwargs)\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tools:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\lmi\\llms.py:501\u001b[39m, in \u001b[36mrequest_limited.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    498\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m item\n\u001b[32m    500\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m request_limited_generator()\n\u001b[32m--> \u001b[39m\u001b[32m501\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\lmi\\llms.py:456\u001b[39m, in \u001b[36mrate_limited.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    453\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m rate_limited_generator()\n\u001b[32m    455\u001b[39m \u001b[38;5;66;03m# We checked isasyncgenfunction above, so this must be an Awaitable\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m func.\u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33macompletion\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.check_rate_limit(\u001b[38;5;28msum\u001b[39m(r.completion_count \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\lmi\\llms.py:674\u001b[39m, in \u001b[36mLiteLLMModel.acompletion\u001b[39m\u001b[34m(self, messages, **kwargs)\u001b[39m\n\u001b[32m    669\u001b[39m \u001b[38;5;66;03m# cast is necessary for LiteLLM typing bug: https://github.com/BerriAI/litellm/issues/7641\u001b[39;00m\n\u001b[32m    670\u001b[39m prompts = cast(\n\u001b[32m    671\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlist[litellm.types.llms.openai.AllMessageValues]\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    672\u001b[39m     [m.model_dump(by_alias=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages],\n\u001b[32m    673\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m674\u001b[39m completions = \u001b[38;5;28;01mawait\u001b[39;00m track_costs(\u001b[38;5;28mself\u001b[39m.router.acompletion)(\n\u001b[32m    675\u001b[39m     \u001b[38;5;28mself\u001b[39m.name, prompts, **kwargs\n\u001b[32m    676\u001b[39m )\n\u001b[32m    677\u001b[39m used_model = completions.model \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name\n\u001b[32m    678\u001b[39m results: \u001b[38;5;28mlist\u001b[39m[LLMResult] = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\lmi\\cost_tracker.py:91\u001b[39m, in \u001b[36mtrack_costs.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped_func\u001b[39m(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs)\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m GLOBAL_COST_TRACKER.enabled.get():\n\u001b[32m     93\u001b[39m         GLOBAL_COST_TRACKER.record(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\router.py:961\u001b[39m, in \u001b[36mRouter.acompletion\u001b[39m\u001b[34m(self, model, messages, stream, **kwargs)\u001b[39m\n\u001b[32m    952\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    953\u001b[39m     asyncio.create_task(\n\u001b[32m    954\u001b[39m         send_llm_exception_alert(\n\u001b[32m    955\u001b[39m             litellm_router_instance=\u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    959\u001b[39m         )\n\u001b[32m    960\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m961\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\router.py:937\u001b[39m, in \u001b[36mRouter.acompletion\u001b[39m\u001b[34m(self, model, messages, stream, **kwargs)\u001b[39m\n\u001b[32m    935\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.schedule_acompletion(**kwargs)\n\u001b[32m    936\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m937\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.async_function_with_fallbacks(**kwargs)\n\u001b[32m    938\u001b[39m end_time = time.time()\n\u001b[32m    939\u001b[39m _duration = end_time - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\router.py:3423\u001b[39m, in \u001b[36mRouter.async_function_with_fallbacks\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3416\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fallback_failure_exception_str) > \u001b[32m0\u001b[39m:\n\u001b[32m   3417\u001b[39m         original_exception.message += (  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m   3418\u001b[39m             \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mError doing the fallback: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   3419\u001b[39m                 fallback_failure_exception_str\n\u001b[32m   3420\u001b[39m             )\n\u001b[32m   3421\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m3423\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m original_exception\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\router.py:3237\u001b[39m, in \u001b[36mRouter.async_function_with_fallbacks\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3233\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.async_function_with_retries(\n\u001b[32m   3234\u001b[39m         *args, **kwargs, mock_timeout=mock_timeout\n\u001b[32m   3235\u001b[39m     )\n\u001b[32m   3236\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3237\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.async_function_with_retries(*args, **kwargs)\n\u001b[32m   3238\u001b[39m verbose_router_logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAsync Response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   3239\u001b[39m response = add_fallback_headers_to_response(\n\u001b[32m   3240\u001b[39m     response=response,\n\u001b[32m   3241\u001b[39m     attempted_fallbacks=\u001b[32m0\u001b[39m,\n\u001b[32m   3242\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\router.py:3532\u001b[39m, in \u001b[36mRouter.async_function_with_retries\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3523\u001b[39m (\n\u001b[32m   3524\u001b[39m     _healthy_deployments,\n\u001b[32m   3525\u001b[39m     _all_deployments,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3528\u001b[39m     parent_otel_span=parent_otel_span,\n\u001b[32m   3529\u001b[39m )\n\u001b[32m   3531\u001b[39m \u001b[38;5;66;03m# raises an exception if this error should not be retries\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3532\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshould_retry_this_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3533\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3534\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhealthy_deployments\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_healthy_deployments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3535\u001b[39m \u001b[43m    \u001b[49m\u001b[43mall_deployments\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_all_deployments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext_window_fallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext_window_fallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mregular_fallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent_policy_fallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontent_policy_fallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3539\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3541\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   3542\u001b[39m     \u001b[38;5;28mself\u001b[39m.retry_policy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3543\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_group_retry_policy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3544\u001b[39m ):\n\u001b[32m   3545\u001b[39m     \u001b[38;5;66;03m# get num_retries from retry policy\u001b[39;00m\n\u001b[32m   3546\u001b[39m     _retry_policy_retries = \u001b[38;5;28mself\u001b[39m.get_num_retries_from_retry_policy(\n\u001b[32m   3547\u001b[39m         exception=original_exception, model_group=kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   3548\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\router.py:3706\u001b[39m, in \u001b[36mRouter.should_retry_this_error\u001b[39m\u001b[34m(self, error, healthy_deployments, all_deployments, context_window_fallbacks, content_policy_fallbacks, regular_fallbacks)\u001b[39m\n\u001b[32m   3703\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[32m   3705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, litellm.NotFoundError):\n\u001b[32m-> \u001b[39m\u001b[32m3706\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[32m   3707\u001b[39m \u001b[38;5;66;03m# Error we should only retry if there are other deployments\u001b[39;00m\n\u001b[32m   3708\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, openai.RateLimitError):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\router.py:3506\u001b[39m, in \u001b[36mRouter.async_function_with_retries\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3502\u001b[39m \u001b[38;5;28mself\u001b[39m._handle_mock_testing_rate_limit_error(\n\u001b[32m   3503\u001b[39m     model_group=model_group, kwargs=kwargs\n\u001b[32m   3504\u001b[39m )\n\u001b[32m   3505\u001b[39m \u001b[38;5;66;03m# if the function call is successful, no exception will be raised and we'll break out of the loop\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3506\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.make_call(original_function, *args, **kwargs)\n\u001b[32m   3507\u001b[39m response = add_retry_headers_to_response(\n\u001b[32m   3508\u001b[39m     response=response, attempted_retries=\u001b[32m0\u001b[39m, max_retries=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3509\u001b[39m )\n\u001b[32m   3510\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\router.py:3624\u001b[39m, in \u001b[36mRouter.make_call\u001b[39m\u001b[34m(self, original_function, *args, **kwargs)\u001b[39m\n\u001b[32m   3622\u001b[39m response = original_function(*args, **kwargs)\n\u001b[32m   3623\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inspect.iscoroutinefunction(response) \u001b[38;5;129;01mor\u001b[39;00m inspect.isawaitable(response):\n\u001b[32m-> \u001b[39m\u001b[32m3624\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m response\n\u001b[32m   3625\u001b[39m \u001b[38;5;66;03m## PROCESS RESPONSE HEADERS\u001b[39;00m\n\u001b[32m   3626\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.set_response_headers(\n\u001b[32m   3627\u001b[39m     response=response, model_group=model_group\n\u001b[32m   3628\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\router.py:1100\u001b[39m, in \u001b[36mRouter._acompletion\u001b[39m\u001b[34m(self, model, messages, **kwargs)\u001b[39m\n\u001b[32m   1098\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1099\u001b[39m     \u001b[38;5;28mself\u001b[39m.fail_calls[model_name] += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1100\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\router.py:1059\u001b[39m, in \u001b[36mRouter._acompletion\u001b[39m\u001b[34m(self, model, messages, **kwargs)\u001b[39m\n\u001b[32m   1052\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1053\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.async_routing_strategy_pre_call_checks(\n\u001b[32m   1054\u001b[39m         deployment=deployment,\n\u001b[32m   1055\u001b[39m         logging_obj=logging_obj,\n\u001b[32m   1056\u001b[39m         parent_otel_span=parent_otel_span,\n\u001b[32m   1057\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1059\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m _response\n\u001b[32m   1061\u001b[39m \u001b[38;5;66;03m## CHECK CONTENT FILTER ERROR ##\u001b[39;00m\n\u001b[32m   1062\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, ModelResponse):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\utils.py:1460\u001b[39m, in \u001b[36mclient.<locals>.wrapper_async\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1458\u001b[39m timeout = _get_wrapper_timeout(kwargs=kwargs, exception=e)\n\u001b[32m   1459\u001b[39m \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m, timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1460\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\utils.py:1321\u001b[39m, in \u001b[36mclient.<locals>.wrapper_async\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1318\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _caching_handler_response.final_embedding_cached_response\n\u001b[32m   1320\u001b[39m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1321\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m original_function(*args, **kwargs)\n\u001b[32m   1322\u001b[39m end_time = datetime.datetime.now()\n\u001b[32m   1323\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\main.py:497\u001b[39m, in \u001b[36macompletion\u001b[39m\u001b[34m(model, messages, functions, function_call, timeout, temperature, top_p, n, stream, stream_options, stop, max_tokens, max_completion_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, parallel_tool_calls, logprobs, top_logprobs, deployment_id, reasoning_effort, base_url, api_version, api_key, model_list, extra_headers, thinking, **kwargs)\u001b[39m\n\u001b[32m    495\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    496\u001b[39m     custom_llm_provider = custom_llm_provider \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mopenai\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m497\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mexception_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43moriginal_exception\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\litellm_core_utils\\exception_mapping_utils.py:2217\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   2215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exception_mapping_worked:\n\u001b[32m   2216\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mlitellm_response_headers\u001b[39m\u001b[33m\"\u001b[39m, litellm_response_headers)\n\u001b[32m-> \u001b[39m\u001b[32m2217\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   2218\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2219\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m error_type \u001b[38;5;129;01min\u001b[39;00m litellm.LITELLM_EXCEPTION_TYPES:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\robin\\.venv\\Lib\\site-packages\\litellm\\litellm_core_utils\\exception_mapping_utils.py:296\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m    292\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minvalid_request_error\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_str\n\u001b[32m    293\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmodel_not_found\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_str\n\u001b[32m    294\u001b[39m ):\n\u001b[32m    295\u001b[39m     exception_mapping_worked = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NotFoundError(\n\u001b[32m    297\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    298\u001b[39m         llm_provider=custom_llm_provider,\n\u001b[32m    299\u001b[39m         model=model,\n\u001b[32m    300\u001b[39m         response=\u001b[38;5;28mgetattr\u001b[39m(original_exception, \u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    301\u001b[39m         litellm_debug_info=extra_information,\n\u001b[32m    302\u001b[39m     )\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mA timeout occurred\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_str:\n\u001b[32m    304\u001b[39m     exception_mapping_worked = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mNotFoundError\u001b[39m: litellm.NotFoundError: OpenAIException - Your organization must be verified to use the model `o4-mini`. Please go to: https://platform.openai.com/settings/organization/general and click on Verify Organization. If you just verified, it can take up to 15 minutes for access to propagate.. Received Model Group=o4-mini\nAvailable Model Group Fallbacks=None"
     ]
    }
   ],
   "source": [
    "from robin.assays import experimental_assay\n",
    "\n",
    "result = await experimental_assay(configuration=cfg)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from robin.assays import experimental_assay\n",
    "from robin.candidates import therapeutic_candidates\n",
    "from robin.configuration import RobinConfiguration\n",
    "from robin.configuration import RobinConfiguration\n",
    "config = RobinConfiguration(llm_model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robin Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RobinConfiguration(disease_name=\"dry age-related macular degeneration\")\n",
    "\n",
    "logger = logging.getLogger(\"robin\")\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial therapeutics hypothesis generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental assay generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_generation_goal = await experimental_assay(configuration=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Therapeutic candidate generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await therapeutic_candidates(\n",
    "    candidate_generation_goal=candidate_generation_goal, configuration=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Therapeutic hypothesis generation with experimental data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running this part of Robin requires access to the Finch data analysis agent, which is currently in a closed beta. Sign up to be a beta tester here: [bit.ly/finchbeta](www.bit.ly/finchbeta). The `robin_full.ipynb notebook` shows an example of the usage of therapeutic hypothesis generation with experimental data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
